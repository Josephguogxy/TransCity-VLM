<p align="center">
  <img src="assets/TransCityLogo.svg" alt="TransCity-VLM Logo" width="180">
</p>

# An Interpretable Visionâ€“Language Foundation Model for Sustainable Smart Cities with Physical World Data-to-Reasoning Traceability

[![License](https://img.shields.io/badge/license-See%20LICENSE-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.10%2B-brightgreen.svg)](#environment)
[![PyTorch](https://img.shields.io/badge/pytorch-required-orange.svg)](#environment)

A research-oriented codebase for **multimodal forecasting** (e.g., traffic flow / electricity load) with a **multi-stage training pipeline**:

- **Stage-A**: multimodal warm-up / alignment
- **Stage-B**: supervised multi-task training
- **Stage-C**: further tuning
- **Stage-D**: RL-style fine-tuning for reasoning quality

> âš ï¸ Data and checkpoints are not shipped. You must prepare your own JSONL datasets and model weights.

---

## ðŸ”¥ News

- [2025.12.30] Initial open-source release.

---

## âœ¨ Demos / Figures

---

## Brief Introduction

This repository implements a multimodal LLM-based forecasting workflow. Each sample can include:

- **Text chunks** (e.g., POI / News / Accident / HopSensor / HopBA)
- **Optional images** (paths/URIs)
- A **prompt** formatted for chat-style decoders (example: Qwen3 chat template)

The core pipeline uses:

- Hugging Face Transformers (`Trainer`, `TrainingArguments`)
- DeepSpeed ZeRO for distributed training (Stage-A/B scripts)
- A unified JSONL data schema normalized by `dataprocessing.py`
- Optional RL fine-tuning via GRPO

---

## Getting Started

### Table of Contents

- [Code Structure](#code-structure)
- [Environment](#environment)
- [Data Format](#data-format)
- [Training](#training)
  - [Stage A](#stage-a)
  - [Stage B](#stage-b)
  - [Stage C](#stage-c)
  - [Stage-D](#Stage-d)
- [Inference & Evaluation](#inference--evaluation)
- [Serving / Integration](#serving--integration)
- [Tokenizer & Vocab Policy (No New Tokens)](#tokenizer--vocab-policy-no-new-tokens)
- [License Notices](#license-notices)
- [Citation](#citation)
- [Acknowledgements](#acknowledgements)

---

## Code Structure

A simplified layout (some folders omitted):

```text
TransCity-VLM
/
â”œâ”€ LICENSE_NOTICES.md
â”œâ”€ dataprocessing.py
â”œâ”€ ds_config_zero3.json
â”œâ”€ LICENSE
â”œâ”€ LICENSE-APACHE-2.0.txt
â”œâ”€ requirements.txt
â”œâ”€ README.md
â”œâ”€ ds_config_zero3_hfopt.json
â”œâ”€ ds_config_zero2.json
â”œâ”€ model/
â”‚  â”œâ”€ builder.py
â”‚  â”œâ”€ decoder_mixlora.py
â”‚  â”œâ”€ mixlora_masked.py
â”‚  â”œâ”€ language_model/
â”‚  â”‚  â””â”€ smartcity_llm.py
â”‚  â”œâ”€ multimodal_encoder/
â”‚  â”‚  â”œâ”€ chunk_text_encoder.py
â”‚  â”‚  â”œâ”€ imagebind_encoder.py
â”‚  â”‚  â””â”€ imagebind/
â”‚  â”‚     â”œâ”€ data.py
â”‚  â”‚     â”œâ”€ requirements.txt
â”‚  â”‚     â”œâ”€ LICENSE-CC-BY-NC-4.0.txt
â”‚  â”‚     â”œâ”€ LICENSE
â”‚  â”‚     â”œâ”€ bpe/
â”‚  â”‚     â”‚  â””â”€ bpe_simple_vocab_16e6.txt.gz
â”‚  â”‚     â””â”€ models/
â”‚  â”‚        â”œâ”€ helpers.py
â”‚  â”‚        â”œâ”€ imagebind_model.py
â”‚  â”‚        â”œâ”€ multimodal_preprocessors.py
â”‚  â”‚        â””â”€ transformer.py
â”‚  â”œâ”€ multimodal_projector/
â”‚  â”‚  â”œâ”€ group.py
â”‚  â”‚  â”œâ”€ projector.py
â”‚  â”‚  â””â”€ vpma.py
â”‚  â””â”€ reinforcement_learning/
â”‚     â”œâ”€ config.py
â”‚     â”œâ”€ logprobs.py
â”‚     â”œâ”€ loss.py
â”‚     â”œâ”€ rewards.py
â”‚     â””â”€ rollout.py
â”œâ”€ agentic_system/
â”‚  â”œâ”€ cli.py
â”‚  â”œâ”€ config.py
â”‚  â”œâ”€ schemas.py
â”‚  â”œâ”€ agents/
â”‚  â”‚  â”œâ”€ base.py
â”‚  â”‚  â”œâ”€ bootstrap/
â”‚  â”‚  â”‚  â”œâ”€ geocode_forward.py
â”‚  â”‚  â”‚  â”œâ”€ nl_parse.py
â”‚  â”‚  â”‚  â”œâ”€ normalize.py
â”‚  â”‚  â”‚  â””â”€ time_window.py
â”‚  â”‚  â”œâ”€ demographics/
â”‚  â”‚  â”‚  â””â”€ demographics.py
â”‚  â”‚  â”œâ”€ geo/
â”‚  â”‚  â”‚  â””â”€ geocode_reverse.py
â”‚  â”‚  â”œâ”€ osm/
â”‚  â”‚  â”‚  â”œâ”€ poi.py
â”‚  â”‚  â”‚  â””â”€ roads.py
â”‚  â”‚  â”œâ”€ record/
â”‚  â”‚  â”‚  â””â”€ record_builder.py
â”‚  â”‚  â”œâ”€ satellite/
â”‚  â”‚  â”‚  â”œâ”€ fetch_gibs.py
â”‚  â”‚  â”‚  â””â”€ store_mysql.py
â”‚  â”‚  â”œâ”€ traffic/
â”‚  â”‚  â”‚  â”œâ”€ nearest_sensor.py
â”‚  â”‚  â”‚  â””â”€ traffic_flow.py
â”‚  â”‚  â”œâ”€ weather/
â”‚  â”‚  â”‚  â””â”€ weather.py
â”‚  â”‚  â””â”€ web/
â”‚  â”‚     â”œâ”€ content_fetcher.py
â”‚  â”‚     â”œâ”€ events.py
â”‚  â”‚     â”œâ”€ query_generator.py
â”‚  â”‚     â”œâ”€ scoring.py
â”‚  â”‚     â””â”€ web_search_agent.py
â”‚  â”œâ”€ clients/
â”‚  â”‚  â”œâ”€ cds.py
â”‚  â”‚  â”œâ”€ census.py
â”‚  â”‚  â”œâ”€ gibs.py
â”‚  â”‚  â”œâ”€ http.py
â”‚  â”‚  â”œâ”€ nominatim.py
â”‚  â”‚  â”œâ”€ open_meteo.py
â”‚  â”‚  â”œâ”€ overpass.py
â”‚  â”‚  â”œâ”€ web_search.py
â”‚  â”‚  â””â”€ worldpop.py
â”‚  â”œâ”€ core/
â”‚  â”‚  â”œâ”€ context.py
â”‚  â”‚  â”œâ”€ executor.py
â”‚  â”‚  â”œâ”€ logging.py
â”‚  â”‚  â”œâ”€ plan_builder.py
â”‚  â”‚  â””â”€ runner.py
â”‚  â”œâ”€ db/
â”‚  â”‚  â”œâ”€ flow_repo.py
â”‚  â”‚  â”œâ”€ mysql_pool.py
â”‚  â”‚  â””â”€ satellite_images_repo.py
â”‚  â”œâ”€ llm/
â”‚  â”‚  â”œâ”€ clients.py
â”‚  â”‚  â””â”€ prompts/
â”‚  â”‚     â””â”€ __init__.py
â”‚  â””â”€ utils/
â”‚     â”œâ”€ geo.py
â”‚     â””â”€ time.py
â”œâ”€ trl/
â”œâ”€ utils/
â”‚  â””â”€ mixed_pr_sampler.py
â”œâ”€ train/
â”‚  â”œâ”€ train_mm_stageA.py
â”‚  â”œâ”€ train_mm_stageB.py
â”‚  â”œâ”€ train_mm_stageC.py
â”‚  â”œâ”€ train_mm_stageD.py
â”‚  â”œâ”€ run_grpo.sh
â”‚  â”œâ”€ run_stageA_ds.sh
â”‚  â”œâ”€ run_stageB_ds.sh
â”‚  â””â”€ run_stageC_ds.sh
â””â”€ eval/
   â”œâ”€ inference_mm_stageB.py
   â”œâ”€ run_inference_stageB.sh
   â”œâ”€ inference_mm_stageA.py
   â”œâ”€ inference_mm_stageC.py
   â”œâ”€ run_inference_stageA.sh
   â””â”€ run_inference_stageC.sh
```

---

## Environment

### Option 1: venv

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### Option 2: conda (example)

```bash
conda create -n trafficPrediction python=3.10 -y
conda activate trafficPrediction
pip install -r requirements.txt
```

---

## Training

> All `run_*.sh` scripts are templates: they avoid internal absolute paths and rely on env vars / editable defaults.

### Stage A

```bash
export DECODER_NAME_OR_PATH="your-decoder-model-or-local-path"
export ENCODER_NAME_OR_PATH="your-encoder-model-or-local-path"
export TRAIN_FILES="dataset_stageA/train_understand_dataset.jsonl"
export VAL_FILES="dataset_stageA/test_understand_dataset.jsonl"
export OUTPUT_DIR="outputs/stageA"

bash run_stageA_ds.sh
```

### Stage B

```bash
export DECODER_NAME_OR_PATH="your-decoder-model-or-local-path"
export ENCODER_NAME_OR_PATH="your-encoder-model-or-local-path"
export FULL_MODEL_LOAD_DIR="outputs/stageA"
export TRAIN_FILES="dataset_stageB/train_*.jsonl"
export VAL_FILES="dataset_stageB/val_*.jsonl"
export OUTPUT_DIR="outputs/stageB"

bash run_stageB_ds.sh
```

### Stage C

```bash
export DECODER_NAME_OR_PATH="your-decoder-model-or-local-path"
export ENCODER_NAME_OR_PATH="your-encoder-model-or-local-path"
export FULL_MODEL_LOAD_DIR="outputs/stageB"
export TRAIN_FILES="dataset_stageC/train_*.jsonl"
export VAL_FILES="dataset_stageC/val_*.jsonl"
export OUTPUT_DIR="outputs/stageC"

bash run_stageC_ds.sh
```

### Stage-D

```bash
export SFT_DIR="outputs/stageC"
export TRAIN_FILES="dataset_rl/train_reason.jsonl"
export OUTPUT_DIR="outputs/grpo"

bash run_grpo.sh
```

---

## Inference & Evaluation

This repo typically evaluates by:

1) generating text outputs,
2) extracting numeric sequences,
3) computing MAE/MSE/RMSE/MAPE/wMAPE,
4) saving `labels_*.txt`, `preds_*.txt`, `metrics_*.json`, and per-rank `raw_*.jsonl`.

---

## License Notices

This repository may contain **multiple licenses**:

- See `LICENSE` for the repository-level license.
- See `THIRD_PARTY_NOTICES.md` for bundled/third-party components and their licenses.
- Some components (e.g., certain multimodal encoders) may be **non-commercial** â€” check carefully before commercial usage.

---

## Citation

If you use this repository in your work, you can cite it as:

```bibtex
@misc{trafficPrediction,
  title        = {trafficPrediction: SmartCityLLM Multimodal Forecasting},
  author       = {torchtorch Authors},
  year         = {2025},
  howpublished = {https://github.com/<your-org-or-user>/trafficPrediction},
}
```

---

## Acknowledgements

This codebase builds on open-source libraries such as:

- PyTorch
- Hugging Face Transformers / Datasets
- DeepSpeed (for distributed training)
- Accelerate / TRL for RL-related utilities

We thank the open-source community for these tools.